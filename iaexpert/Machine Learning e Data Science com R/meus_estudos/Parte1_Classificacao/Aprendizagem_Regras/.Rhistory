setwd("~/Estudos_R/altabooks")
setwd("~/Estudos_R/iaexpert/Machine Learning e Data Science com R/meus_estudos/Parte1_Classificacao/Aprendizagem_Arvore_Decisao")
# Leitura da base de dados
base = read.csv('census.csv')
# Apagar a coluna X
base$X = NULL
# Tratamento dos campos categóricos
base$workclass = factor(base$workclass, levels = c(' Federal-gov', ' Local-gov', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$education = factor(base$education, levels = c(' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16))
base$marital.status = factor(base$marital.status, levels = c(' Divorced', ' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$occupation = factor(base$occupation, levels = c(' Adm-clerical', ' Armed-Forces', ' Craft-repair', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
base$relationship = factor(base$relationship, levels = c(' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife'), labels = c(1, 2, 3, 4, 5, 6))
base$race = factor(base$race, levels = c(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), labels = c(1, 2, 3, 4, 5))
base$sex = factor(base$sex, levels = c(' Female', ' Male'), labels = c(0, 1))
base$native.country = factor(base$native.country, levels = c(' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41))
base$income = factor(base$income, levels = c(' <=50K', ' >50K'), labels = c(0, 1))
# Escalonamento
base[, 1] = scale(base[, 1])
base[, 3] = scale(base[, 3])
base[, 5] = scale(base[, 5])
base[, 11:13] = scale(base[, 11:13])
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.85)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
library(rpart)
classificador = rpart(formula = income ~., data = base_treinamento)
rpart.plot(classificador)
previsoes = predict(classificador, newdata = base_teste[-15], type = 'class')
matriz_confusao = table(base_teste[, 15], previsoes)
library(caret)
confusionMatrix(matriz_confusao)
# Leitura da base de dados
base = read.csv('census.csv')
# Apagar a coluna X
base$X = NULL
# Tratamento dos campos categóricos
base$workclass = factor(base$workclass, levels = c(' Federal-gov', ' Local-gov', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$education = factor(base$education, levels = c(' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16))
base$marital.status = factor(base$marital.status, levels = c(' Divorced', ' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$occupation = factor(base$occupation, levels = c(' Adm-clerical', ' Armed-Forces', ' Craft-repair', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
base$relationship = factor(base$relationship, levels = c(' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife'), labels = c(1, 2, 3, 4, 5, 6))
base$race = factor(base$race, levels = c(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), labels = c(1, 2, 3, 4, 5))
base$sex = factor(base$sex, levels = c(' Female', ' Male'), labels = c(0, 1))
base$native.country = factor(base$native.country, levels = c(' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41))
base$income = factor(base$income, levels = c(' <=50K', ' >50K'), labels = c(0, 1))
# Escalonamento
base[, 1] = scale(base[, 1])
base[, 3] = scale(base[, 3])
base[, 5] = scale(base[, 5])
base[, 11:13] = scale(base[, 11:13])
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.85)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
library(rpart.plot)
classificador = rpart(formula = income ~., data = base_treinamento)
rpart.plot(classificador)
previsoes = predict(classificador, newdata = base_teste[-15], type = 'class')
matriz_confusao = table(base_teste[, 15], previsoes)
library(caret)
confusionMatrix(matriz_confusao)
libary(rpart)
poda = classificador$cptable[which.min(classificador$cptable[, "xerror"]), "CP"]
# Realiza a poda na árvore de decisão com base no valor da variável poda
prune(classificador,poda)
library(rpart)
poda = classificador$cptable[which.min(classificador$cptable[, "xerror"]), "CP"]
# Realiza a poda na árvore de decisão com base no valor da variável poda
prune(classificador,poda)
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Apaga a coluna clientid
base$clientid = NULL
# Valores inconsistentes
base$age = ifelse(base$age < 0, 40.92, base$age)
# Valores faltantes
base$age = ifelse(is.na(base$age), mean(base$age, na.rm = TRUE), base$age)
# Escalonamento
base[, 1:3] = scale(base[, 1:3])
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR
table(base_teste$default)
install.packages('randomForest')
library(randomForest)
library(randomForest)
classificador = randomForest(x = base_treinamento, y = base_treinamento[-4], ntree = 10)
classificador = randomForest(x = base_treinamento[-4], y = base_treinamento$default, ntree = 10)
# Encode
base$default = factor(base$default, levels = c(0,1))
# Encode
base$default = factor(base$default, levels = c(0,1))
classificador = randomForest(x = base_treinamento[-4], y = base_treinamento$default, ntree = 10)
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Apaga a coluna clientid
base$clientid = NULL
# Valores inconsistentes
base$age = ifelse(base$age < 0, 40.92, base$age)
# Valores faltantes
base$age = ifelse(is.na(base$age), mean(base$age, na.rm = TRUE), base$age)
# Escalonamento
base[, 1:3] = scale(base[, 1:3])
# Encode
base$default = factor(base$default, levels = c(0,1))
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR
table(base_teste$default)
install.packages('randomForest')
library(randomForest)
classificador = randomForest(x = base_treinamento[-4], y = base_treinamento$default, ntree = 10)
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Apaga a coluna clientid
base$clientid = NULL
# Valores inconsistentes
base$age = ifelse(base$age < 0, 40.92, base$age)
# Valores faltantes
base$age = ifelse(is.na(base$age), mean(base$age, na.rm = TRUE), base$age)
# Escalonamento
base[, 1:3] = scale(base[, 1:3])
# Encode
base$default = factor(base$default, levels = c(0,1))
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR
table(base_teste$default)
install.packages('randomForest')
library(randomForest)
classificador = randomForest(x = base_treinamento[-4], y = base_treinamento$default, ntree = 10)
install.packages("randomForest")
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Apaga a coluna clientid
base$clientid = NULL
# Valores inconsistentes
base$age = ifelse(base$age < 0, 40.92, base$age)
# Valores faltantes
base$age = ifelse(is.na(base$age), mean(base$age, na.rm = TRUE), base$age)
# Escalonamento
base[, 1:3] = scale(base[, 1:3])
# Encode
base$default = factor(base$default, levels = c(0,1))
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR
table(base_teste$default)
install.packages('randomForest')
library(randomForest)
classificador = randomForest(x = base_treinamento[-4], y = base_treinamento$default, ntree = 10)
previsoes = predict(classificador, newdata = base_teste[-4])
matriz_confusao = table(base_teste[, 4], previsoes)
library(caret)
confusionMatrix(matriz_confusao)
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Apaga a coluna clientid
base$clientid = NULL
# Valores inconsistentes
base$age = ifelse(base$age < 0, 40.92, base$age)
# Valores faltantes
base$age = ifelse(is.na(base$age), mean(base$age, na.rm = TRUE), base$age)
# Escalonamento
base[, 1:3] = scale(base[, 1:3])
# Encode
base$default = factor(base$default, levels = c(0,1))
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
install.packages('randomForest')
library(randomForest)
set.seed(1)
classificador = randomForest(x = base_treinamento[-4], y = base_treinamento$default, ntree = 10)
previsoes = predict(classificador, newdata = base_teste[-4])
matriz_confusao = table(base_teste[, 4], previsoes)
library(caret)
confusionMatrix(matriz_confusao)
install.packages("randomForest")
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Apaga a coluna clientid
base$clientid = NULL
# Valores inconsistentes
base$age = ifelse(base$age < 0, 40.92, base$age)
# Valores faltantes
base$age = ifelse(is.na(base$age), mean(base$age, na.rm = TRUE), base$age)
# Escalonamento
base[, 1:3] = scale(base[, 1:3])
# Encode
base$default = factor(base$default, levels = c(0,1))
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# install.packages('randomForest')
library(randomForest)
set.seed(1)
classificador = randomForest(x = base_treinamento[-4], y = base_treinamento$default, ntree = 10)
previsoes = predict(classificador, newdata = base_teste[-4])
matriz_confusao = table(base_teste[, 4], previsoes)
library(caret)
confusionMatrix(matriz_confusao)
# Leitura da base de dados
base = read.csv('census.csv')
# Apagar a coluna X
base$X = NULL
# Tratamento dos campos categóricos
base$workclass = factor(base$workclass, levels = c(' Federal-gov', ' Local-gov', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$education = factor(base$education, levels = c(' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16))
base$marital.status = factor(base$marital.status, levels = c(' Divorced', ' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$occupation = factor(base$occupation, levels = c(' Adm-clerical', ' Armed-Forces', ' Craft-repair', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
base$relationship = factor(base$relationship, levels = c(' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife'), labels = c(1, 2, 3, 4, 5, 6))
base$race = factor(base$race, levels = c(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), labels = c(1, 2, 3, 4, 5))
base$sex = factor(base$sex, levels = c(' Female', ' Male'), labels = c(0, 1))
base$native.country = factor(base$native.country, levels = c(' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41))
base$income = factor(base$income, levels = c(' <=50K', ' >50K'), labels = c(0, 1))
# Escalonamento
base[, 1] = scale(base[, 1])
base[, 3] = scale(base[, 3])
base[, 5] = scale(base[, 5])
base[, 11:13] = scale(base[, 11:13])
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.85)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR - base line classifier (linha base)
table(base_teste$income)
library(randomForest)
set.seed(1)
classificador = randomForest(x = base_treinamento[-15], y = base_treinamento$income, ntree = 10)
# Leitura da base de dados
base = read.csv('census.csv')
# Apagar a coluna X
base$X = NULL
# Tratamento dos campos categóricos
base$workclass = factor(base$workclass, levels = c(' Federal-gov', ' Local-gov', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$education = factor(base$education, levels = c(' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16))
base$marital.status = factor(base$marital.status, levels = c(' Divorced', ' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$occupation = factor(base$occupation, levels = c(' Adm-clerical', ' Armed-Forces', ' Craft-repair', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
base$relationship = factor(base$relationship, levels = c(' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife'), labels = c(1, 2, 3, 4, 5, 6))
base$race = factor(base$race, levels = c(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), labels = c(1, 2, 3, 4, 5))
base$sex = factor(base$sex, levels = c(' Female', ' Male'), labels = c(0, 1))
base$native.country = factor(base$native.country, levels = c(' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41))
base$income = factor(base$income, levels = c(' <=50K', ' >50K'), labels = c(0, 1))
# Escalonamento
base[, 1] = scale(base[, 1])
base[, 3] = scale(base[, 3])
base[, 5] = scale(base[, 5])
base[, 11:13] = scale(base[, 11:13])
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.85)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR - base line classifier (linha base)
table(base_teste$income)
library(randomForest)
set.seed(1)
classificador = randomForest(x = base_treinamento[-15], y = base_treinamento$income, ntree = 10)
previsoes = predict(classificador)
previsoes = predict(classificador, newdata = base_teste[-15])
matriz_confusao = table(base_teste[, 15], previsoes)
print(matriz_confusao)
library(caret)
confusionMatrix(matriz_confusao)
setwd("~/Estudos_R/iaexpert/Machine Learning e Data Science com R/meus_estudos/Parte1_Classificacao/Aprendizagem_Regras")
base = read.csv('risco_credito.csv')
install.packages('OneR')
# install.packages('OneR')
library(OneR)
base = read.csv('risco_credito.csv')
View(base)
classificador = OneR(base)
View(classificador)
print classificador
print(classificador)
# história: boa, dívida: alta, garantias: nenhuma, renda: >35
# história: ruim, dívida: alta, garantias: adequada, renda: <15
historia = c('boa', 'ruim')
divida = c('alta', 'alta')
garantias = c('nenhuma', 'adequada')
renda = c('acima_35', '0_15')
df = data.frame(historia, divida, garantias, renda)
previsoes = predict(classificador, newdata = df)
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Apaga a coluna clientid
base$clientid = NULL
# Valores inconsistentes
base$age = ifelse(base$age < 0, 40.92, base$age)
# Valores faltantes
base$age = ifelse(is.na(base$age), mean(base$age, na.rm = TRUE), base$age)
# Escalonamento
base[, 1:3] = scale(base[, 1:3])
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR
table(base_teste$default)
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Apaga a coluna clientid
base$clientid = NULL
# Valores inconsistentes
base$age = ifelse(base$age < 0, 40.92, base$age)
# Valores faltantes
base$age = ifelse(is.na(base$age), mean(base$age, na.rm = TRUE), base$age)
# Escalonamento
base[, 1:3] = scale(base[, 1:3])
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR
table(base_teste$default)
install.packages('RoughSets')
#install.packages('RoughSets')
library(RoughSets)
dt_treinamento = SF.asDecisionTable(dataset = base_treinamento, decision.attr = 4)
dt_teste = SF.asDecisionTable(dataset = base_teste, decision.attr = 4)
View(dt_teste)
View(dt_treinamento)
classificador = RI.CN2Rules.RST(dt_treinamento)
classificador = RI.CN2Rules.RST(dt_treinamento, K = 5)
# Leitura da base de dados
base = read.csv('credit_data.csv')
# Apaga a coluna clientid
base$clientid = NULL
# Valores inconsistentes
base$age = ifelse(base$age < 0, 40.92, base$age)
# Valores faltantes
base$age = ifelse(is.na(base$age), mean(base$age, na.rm = TRUE), base$age)
# Escalonamento
# base[, 1:3] = scale(base[, 1:3])
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR
table(base_teste$default)
#install.packages('RoughSets')
library(RoughSets)
dt_treinamento = SF.asDecisionTable(dataset = base_treinamento, decision.attr = 4)
dt_teste = SF.asDecisionTable(dataset = base_teste, decision.attr = 4)
# Categoriza os atributos numéricos gerando intervalos de frequência
intervalos = D.discretization.RST(dt_treinamento, nOfIntervals = 4)
intervalos
dt_treinamento = SF.applyDecTable(dt_treinamento, intervalos)
dt_teste = SF.applyDecTable(dt_teste, intervalos)
dt_treinamento
View(dt_treinamento)
View(dt_treinamento)
classificador = RI.CN2Rules.RST(dt_treinamento, K = 5)
classificador
print(classificador)
previsoes = predict(classificador, newdata = dt_teste[4])
previsoes = predict(classificador, newdata = dt_teste[-4])
previsoes
matriz_confusao = table(dt_teste[, 4], previsoes)
matriz_confusao = table(dt_teste[, 4], unlist(previsoes))
matriz_confusao
library(caret)
confusionMatrix(matriz_confusao)
# Leitura da base de dados
base = read.csv('census.csv')
# Apagar a coluna X
base$X = NULL
# Tratamento dos campos categóricos
base$workclass = factor(base$workclass, levels = c(' Federal-gov', ' Local-gov', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$education = factor(base$education, levels = c(' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16))
base$marital.status = factor(base$marital.status, levels = c(' Divorced', ' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$occupation = factor(base$occupation, levels = c(' Adm-clerical', ' Armed-Forces', ' Craft-repair', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
base$relationship = factor(base$relationship, levels = c(' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife'), labels = c(1, 2, 3, 4, 5, 6))
base$race = factor(base$race, levels = c(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), labels = c(1, 2, 3, 4, 5))
base$sex = factor(base$sex, levels = c(' Female', ' Male'), labels = c(0, 1))
base$native.country = factor(base$native.country, levels = c(' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41))
base$income = factor(base$income, levels = c(' <=50K', ' >50K'), labels = c(0, 1))
# Escalonamento
base[, 1] = scale(base[, 1])
base[, 3] = scale(base[, 3])
base[, 5] = scale(base[, 5])
base[, 11:13] = scale(base[, 11:13])
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.85)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR - base line classifier (linha base)
table(base_teste$income)
# Leitura da base de dados
base = read.csv('census.csv')
# Apagar a coluna X
base$X = NULL
# Para algoritmos baseados em regras não é interessante categorizar nem escalonar atributos
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.85)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR - base line classifier (linha base)
table(base_teste$income)
library(RoughSets)
dt_treinamento = SF.asDecisionTable(dataset = base_treinamento, decision.attr = 4)
dt_treinamento = SF.asDecisionTable(dataset = base_treinamento, decision.attr = 15)
dt_teste = SF.asDecisionTable(dataset = base_teste, decision.attr = 15)
# Categoriza os atributos numéricos gerando intervalos de frequência
intervalos = D.discretization.RST(dt_treinamento, nOfIntervals = 15)
# Leitura da base de dados
base = read.csv('census.csv')
# Apagar a coluna X
base$X = NULL
# Para algoritmos baseados em regras não é interessante categorizar nem escalonar atributos
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.85)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
library(RoughSets)
dt_treinamento = SF.asDecisionTable(dataset = base_treinamento, decision.attr = 15)
dt_teste = SF.asDecisionTable(dataset = base_teste, decision.attr = 15)
# Categoriza os atributos numéricos gerando intervalos de frequência
intervalos = D.discretization.RST(dt_treinamento, nOfIntervals = 4)
# Substitui os valores numéricos nas bases de treinamento e de teste pelos intervalos calculados acima
dt_treinamento = SF.applyDecTable(dt_treinamento, intervalos)
dt_teste = SF.applyDecTable(dt_teste, intervalos)
classificador = RI.CN2Rules.RST(dt_treinamento, K = 5)
previsoes = predict(classificador, newdata = dt_teste[-15])
matriz_confusao = table(dt_teste[, 15], unlist(previsoes))
library(caret)
confusionMatrix(matriz_confusao)
# Leitura da base de dados
base = read.csv('census.csv')
# Apagar a coluna X
base$X = NULL
# Para algoritmos baseados em regras não é interessante categorizar nem escalonar atributos
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
divisao = sample.split(base$income, SplitRatio = 0.05)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
library(RoughSets)
dt_treinamento = SF.asDecisionTable(dataset = base_treinamento, decision.attr = 15)
dt_teste = SF.asDecisionTable(dataset = base_teste, decision.attr = 15)
# Categoriza os atributos numéricos gerando intervalos de frequência
intervalos = D.discretization.RST(dt_treinamento, nOfIntervals = 4)
# Substitui os valores numéricos nas bases de treinamento e de teste pelos intervalos calculados acima
dt_treinamento = SF.applyDecTable(dt_treinamento, intervalos)
dt_teste = SF.applyDecTable(dt_teste, intervalos)
classificador = RI.CN2Rules.RST(dt_treinamento, K = 1)
previsoes = predict(classificador, newdata = dt_teste[-15])
matriz_confusao = table(dt_teste[, 15], unlist(previsoes))
library(caret)
confusionMatrix(matriz_confusao)
# ZeroR - base line classifier
table(base_teste$income)
# Apagar a coluna X
base$X = NULL
# Para algoritmos baseados em regras não é interessante categorizar nem escalonar atributos
# Divisão entre treinamento e teste
library(caTools)
set.seed(1)
# Esse algoritmo é lento. Por isso está sendo usado apenas 5% da base para treinamento.
divisao = sample.split(base$income, SplitRatio = 0.05)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
# ZeroR - base line classifier
table(base_teste$income)
# ZeroR - base line classifier
table(base_teste$income)
